{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-macosx_10_11_x86_64.whl (198.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 198.9 MB 28 kB/s  eta 0:00:01    |████▉                           | 30.2 MB 2.9 MB/s eta 0:00:59     |█████████████                   | 81.3 MB 1.7 MB/s eta 0:01:08     |██████████████                  | 87.4 MB 2.2 MB/s eta 0:00:51     |██████████████                  | 87.6 MB 2.2 MB/s eta 0:00:51     |███████████████▌                | 96.5 MB 2.5 MB/s eta 0:00:41     |████████████████▎               | 101.2 MB 1.8 MB/s eta 0:00:55     |█████████████████               | 106.2 MB 4.5 MB/s eta 0:00:21     |███████████████████▉            | 123.0 MB 2.5 MB/s eta 0:00:31     |████████████████████▋           | 128.2 MB 2.0 MB/s eta 0:00:37     |██████████████████████▌         | 140.1 MB 2.2 MB/s eta 0:00:28     |███████████████████████         | 142.8 MB 513 kB/s eta 0:01:50     |████████████████████████████▌   | 177.4 MB 928 kB/s eta 0:00:24     |█████████████████████████████▎  | 182.1 MB 2.0 MB/s eta 0:00:09     |██████████████████████████████▍ | 188.7 MB 3.2 MB/s eta 0:00:04     |██████████████████████████████▌ | 189.6 MB 3.2 MB/s eta 0:00:03     |███████████████████████████████▉| 197.9 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp36-cp36m-macosx_10_9_x86_64.whl (960 kB)\n",
      "\u001b[K     |████████████████████████████████| 960 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.6 MB 2.6 MB/s eta 0:00:01    |██                              | 942 kB 2.5 MB/s eta 0:00:06     |██▌                             | 1.2 MB 2.5 MB/s eta 0:00:06     |█████████████                   | 6.3 MB 2.2 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.44.0-cp36-cp36m-macosx_10_10_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 2.2 MB/s eta 0:00:01     |██████                          | 808 kB 2.3 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.0.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (47.1.1.post20200604)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /Users/eleonorajmartin/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.3.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, wrapt, clang\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=39d9524b501e0a891c481b43c1ae375616c50b32d1db4eeba7d5079726f263ec\n",
      "  Stored in directory: /Users/eleonorajmartin/Library/Caches/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-macosx_10_9_x86_64.whl size=32415 sha256=689e1535379e16a8381887d801e80ef120e000cef451ce2b91d4899d1265e15a\n",
      "  Stored in directory: /Users/eleonorajmartin/Library/Caches/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=75174e154f1adaa2a270297fb3fd7f7a6c9b98fb8f97784a5bd38cc7f5d967bf\n",
      "  Stored in directory: /Users/eleonorajmartin/Library/Caches/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "Successfully built termcolor wrapt clang\n",
      "Installing collected packages: keras, numpy, keras-preprocessing, absl-py, termcolor, flatbuffers, wrapt, google-pasta, protobuf, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, wheel, typing-extensions, importlib-metadata, markdown, grpcio, tensorboard-plugin-wit, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, tensorboard, opt-einsum, cached-property, h5py, astunparse, tensorflow-estimator, gast, clang, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "      Successfully uninstalled numpy-1.18.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 2.0.0\n",
      "    Uninstalling importlib-metadata-2.0.0:\n",
      "      Successfully uninstalled importlib-metadata-2.0.0\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.1.0 importlib-metadata-4.8.3 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.6 numpy-1.19.5 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wheel-0.37.1 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5734, 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('big_base.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove diabetes outcome target from features data\n",
    "y = df.region.values\n",
    "X = df.drop(['School','region'], axis=1)\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical data for neural network\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "135/135 [==============================] - 2s 3ms/step - loss: -9.0091 - accuracy: 0.0505\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -64.5273 - accuracy: 0.0514\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 1s 6ms/step - loss: -257.1176 - accuracy: 0.0514\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -691.3605 - accuracy: 0.0514\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -1482.1777 - accuracy: 0.0514\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: -2718.2449 - accuracy: 0.0514\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -4478.1694 - accuracy: 0.0514\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -6812.5488 - accuracy: 0.0514\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -9778.6895 - accuracy: 0.0514\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -13423.8525 - accuracy: 0.0514\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 1s 6ms/step - loss: -17808.0176 - accuracy: 0.0514A: 0s - loss: -15890.0088 - accur\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -22953.9746 - accuracy: 0.0514\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: -28895.1562 - accuracy: 0.0514\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: -35634.7734 - accuracy: 0.0514\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -43238.4023 - accuracy: 0.0514\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -51690.6289 - accuracy: 0.0514\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -61040.6250 - accuracy: 0.0514\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -71273.1250 - accuracy: 0.0514\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -82453.9062 - accuracy: 0.0514\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -94607.1406 - accuracy: 0.0514\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -107725.5703 - accuracy: 0.0514\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -121821.1719 - accuracy: 0.0514\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -136863.2969 - accuracy: 0.0514\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -152952.4375 - accuracy: 0.0514\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -170081.2500 - accuracy: 0.0514\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -188276.7188 - accuracy: 0.0514\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -207542.3281 - accuracy: 0.0514\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -227854.3438 - accuracy: 0.0514\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -249235.1719 - accuracy: 0.0514\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -271682.6250 - accuracy: 0.0514\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -295231.8750 - accuracy: 0.0514\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -319965.7812 - accuracy: 0.0514\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -345868.6250 - accuracy: 0.0514\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -372929.7188 - accuracy: 0.0514\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -401144.0312 - accuracy: 0.0514\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -430573.0312 - accuracy: 0.0514\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -461271.4375 - accuracy: 0.0514\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -493188.0312 - accuracy: 0.0514\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -526265.6875 - accuracy: 0.0514\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -560574.7500 - accuracy: 0.0514\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -596117.3750 - accuracy: 0.0514\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -633030.6875 - accuracy: 0.0514\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -671242.1875 - accuracy: 0.0514\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: -710721.9375 - accuracy: 0.0514\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -751674.1250 - accuracy: 0.0514\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -793903.3125 - accuracy: 0.0514\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -837460.1875 - accuracy: 0.0514\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 2ms/step - loss: -882331.1250 - accuracy: 0.0514\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -928627.2500 - accuracy: 0.0514\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: -976312.5000 - accuracy: 0.0514\n",
      "45/45 - 0s - loss: -1.0164e+06 - accuracy: 0.0516\n",
      "Loss: -1016361.125, Accuracy: 0.051603905856609344\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=13))\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.686\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "      <th>aian</th>\n",
       "      <th>nhpi</th>\n",
       "      <th>tom</th>\n",
       "      <th>ntr</th>\n",
       "      <th>unk</th>\n",
       "      <th>men</th>\n",
       "      <th>women</th>\n",
       "      <th>highest_degree</th>\n",
       "      <th>ownership</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George C Wallace State Community College-Selma</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Herzing University-Birmingham</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huntingdon College</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heritage Christian University</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heritage Christian University</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           School   white   black  hispanic  \\\n",
       "0  George C Wallace State Community College-Selma  0.1644  0.7805    0.0058   \n",
       "1                   Herzing University-Birmingham  0.3168  0.6000    0.0212   \n",
       "2                              Huntingdon College  0.6832  0.1897    0.0497   \n",
       "3                   Heritage Christian University  0.8136  0.0508    0.0678   \n",
       "4                   Heritage Christian University  0.8136  0.0508    0.0678   \n",
       "\n",
       "    asian    aian    nhpi     tom     ntr     unk     men   women  \\\n",
       "0  0.0155  0.0000  0.0000  0.0174  0.0010  0.0155  0.3588  0.6412   \n",
       "1  0.0035  0.0053  0.0053  0.0319  0.0000  0.0159  0.2124  0.7876   \n",
       "2  0.0070  0.0070  0.0000  0.0427  0.0000  0.0209  0.4876  0.5124   \n",
       "3  0.0169  0.0000  0.0000  0.0339  0.0169  0.0000  0.9661  0.0339   \n",
       "4  0.0169  0.0000  0.0000  0.0339  0.0169  0.0000  0.9661  0.0339   \n",
       "\n",
       "   highest_degree  ownership  region  \n",
       "0               2          1       5  \n",
       "1               4          2       5  \n",
       "2               3          2       5  \n",
       "3               4          2       5  \n",
       "4               4          2       5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=800)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.617\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythonData] *",
   "language": "python",
   "name": "conda-env-pythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
